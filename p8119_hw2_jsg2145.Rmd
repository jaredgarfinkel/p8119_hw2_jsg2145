---
title: "p8119_hw2_jsg2145"
author: "Jared Garfinkel"
date: "10/26/2020"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	message = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r}
tibble("Chapter" = c(7, 8, 9), "Problems" = c("1, 2, 3, 4", "7", "1, 2, 3"))
```

# Chapter 7

## Exercise 1

We test for a codominant mode of inheritance using an odds ratio.

```{r}
data = tibble(GM = c("present", "not present"), nsubjects = c(293, 4627), cases = c(23, 1343))
data
tidy_dat = tibble(exposed = c(23, 293-23), unexposed = c(1343, 4627-1343))
tidy_dat
```

```{r}
OR = 23*(4627-1343)/(293-23)/1343
OR
```

The odds ratio is 0.208.

```{r}
var_log_OR = 1/23 + 1/1343 + 1/270 + 1/3284
var_log_OR
SE = sqrt(var_log_OR)
lower = exp(log(OR)-SE*dnorm(0.975))
lower
upper = exp(log(OR)+SE*dnorm(0.975))
upper
```

The confidence interval is (`r round(lower, 3)`, `r round(upper, 3)`). This indicates that there is evidence to suggest that there is a reduced odds of having the exposure in the diseased compared to the non-diseased.

## Problem 2

### Part a

Compute the test statistics for the additive model and the dominant model and compare.

```{r}
df = tibble(disease = c("acne_patient", "control"), GG = c(66, 99), GA = c(43, 15), AA = c(4, 0))
df
dom_df = tibble(disease = c("acne patient", "control"), `AA or GA` = (pull(df, AA) + pull(df, GA)), GG = pull(df, GG))
dom_df
chisq.test(dom_df[,-1]) # p = <0.001
allele_df = tibble(disease = c("acne patient", "control"), A = c(2*4+83, 2*0+15), G = c(2*66+43, 2*99+15))
allele_df
chisq.test(allele_df[,-1]) # p < 0.001
```
These two tests yield similar answers. They both show a high degree of significance in the dominant and additive models.

### Part b

```{r}
var_log_OR = 1/47+1/66+1/15+1/99
log_OR = log(47*99/66/15)
lower = exp(log_OR-sqrt(var_log_OR)*dnorm(0.975))
upper = exp(log_OR+sqrt(var_log_OR)*dnorm(0.975))
```

The confidence interval of the dominant odds ratio is (`r round(lower, 3)`, `r round(upper, 3)`). This makes sense since the chi squared tests yield significant results.

### Part c

```{r}
df
rec_df = tibble(disease = pull(df, disease), `GG or GA` = pull(df, GG) + pull(df, GA), AA = pull(df, AA))
rec_df
fisher.test(rec_df[,-1]) # p = 0.0597
```

This Fisher exact test shows the recessive model is marginally significant at p = 0.0597. However, this is much greater than the significance levels for either the dominant model or the additive model.

## Problem 3

Modes of inheritance: Dominant, codominant, recessive 

```{r}
df_dat = tibble(disease = c("case", "control"), x0 = c(500, 521), x1 = c(350, 270), x2 = c(120, 130), total = x0 + x1 + x2)
df_dat
```

$$K = \gamma_2p_D^2+f_0(1-p_D^2)$$

The odds ratios are relative to a baseline, x0.

```{r}
OR0 = 1
OR1 = 350*521/500/270
OR2 = 120*521/500/130
OR_df = cbind(OR0, OR1, OR2)
round(OR_df, 3)
```

The odds ratio for x = 1 is `r round(OR1, 3)` and for x = 2, OR = `r round(OR2, 3)`.

The confidence intervals are as follows:

```{r}
CI_OR = function(df = df_dat, x = x1, a, b, c, d) {
  b = pull(df, x0)[[1]]
  d = pull(df, x0)[[2]]
  a = pull(df, x)[[1]]
  c = pull(df, x)[[2]]
  var_log_OR = 1/a+1/b+1/c+1/d
  log_OR = log(a*d/b/c)
  lower = exp(log_OR-sqrt(var_log_OR)*dnorm(0.975))
  upper = exp(log_OR+sqrt(var_log_OR)*dnorm(0.975))
  CI = cbind(lower, upper)
  return(CI)
}

CI_x0 = CI_OR(x = "x0")
CI_x1 = CI_OR(x = "x1")
CI_x2 = CI_OR(x = "x2")
```

The confidence intervals are x0: `r round(OR0, 3)` (`r round(CI_x0[[1]], 3)`, `r round(CI_x0[[2]], 3)`), x1: `r round(OR1, 3)`  (`r round(CI_x1[[1]], 3)`, `r round(CI_x1[[2]], 3)`), and x2: `r round(OR2, 3)` (`r round(CI_x2[[1]], 3)`, `r round(CI_x2[[2]], 3)`).

```{r}
df_dat
dom_df = tibble(disease = pull(df_dat, disease), x0 = pull(df_dat, x0), `x1 or x2` = pull(df_dat, x1) + pull(df_dat, x2))
chisq.test(dom_df[,-1]) # p = 0.032
rec_df = tibble(disease = pull(df_dat, disease), `x0 or x1` = pull(df_dat, x0) + pull(df_dat, x1), x2 = pull(df_dat, x2))
chisq.test(rec_df[,-1]) # 0.2932
chisq.test(df_dat[,-1]) # p = 0.01951
```

The dominant and additive model tests are significant, but the recessive model test is not. This indicates that a dominant or additive model may be more appropriate for this data.

# Problem 4

Definitions:

$$n_{DSL} = 2(z_{(1-\beta)}+z_{(1-\alpha/2)})^2p_D(1-p_D)/\Delta_D^2$$

$$\Delta_D = (p_{D|cases}-p_{D|controls})$$

Given:

$\gamma_1 = 1.3$

It follows that under an additive model, $\gamma_2 = 2*\gamma_1-1 = 1.6$

So, $f_1 = 1.3*f_0$ and $f_2 = 1.6*f_0$

Since $\sum_i(f_i)$ = 1,

$(1.3 + 1.6 + 1)*f_0 = 1, f_0 = 1/3.9 =$ `r round(1/3.9, 2)` = p(disease | i copies of the allele)

$f_1 = 1.3*0.26$ = `r 1.3*.26`

$f_2 = 1.6*0.26$ = `r 1.6*0.26`

risk of colon cancer (K) = .04

power = 0.8

$p_D$ = 0.55

So,

$q_{cases} = f_2g_2/K = 0.416*0.55^2/0.04$ = `r round(0.416*0.55^2/0.04, 3)`

$q_{controls} = (1-f_2)g_2/Q$ = `r round((1-0.416)*0.55^2/0.96, 3)`

q = $\frac{r*q_{case} + s*q_{control}}{n}$ = (3.146 + 0.184)/2 = `r (3.146 + 0.184)/2`

$\Delta_D = (q_{cases} - q_{controls})$ = 3.146 - 0.184 = `r 3.146-0.184`

Assume: $\alpha$ = 0.05

r = s = $\frac{2*(z_{(1-\beta)}+z_{(1-\alpha/2)})^2*q(1-q)}{\Delta^2}$

# Chapter 8

## Problem 7

$\hat{\lambda}$

```{r}
data = "5.112124234 0.827057943 3.158134984 3.395351358 0.056900096 0.878446231 4.955161751 0.127185994 1.115390624 1.471334371 0.042577497 0.833171588 0.389633293 0.088260639 0.008057015 0.206122142 0.052385560 0.020823177 1.445823813 0.195321095" %>% 
  str_replace_all(., " ", ",")
data2 = data %>% 
  str_split_fixed(., ",", n = 20) %>% 
  as.numeric()

median = median(data2)

lambda = 0.4549/median

lambda

lambda*data2

qchisq(.95, 1)

which(lambda*data2 > qchisq(.95, 1))
```

There is no evidence for admixture since the inflation factor adjusted chi-squared values for the null markers are less than the chi-squared with 1 df.

The genomic adjustment factor is `r round(lambda, 3)`.

The marker of interest is not associated with affection status in the alleles test or the trend test adjusted for genetic control.

# Chapter 9

## Problem 1

$(x-y)^2/(x+y)$

```{r}
(78-46)^2/(78+46)
```

Confirmed.

## Problem 2

The alternative hypothesis of a TDT is that a marker is both linked and associated with a disease locus underlying the trait.

A rejection of the null in a case-control or cohort study does not necessarily mean an association with a disease locus because of issues with population substructure.

## Problem 3

The TDT is conditioned on the parental genotypes. The null distribution is computed using the distribution of the offspring genotypes conditional on parental genotypes and offspring traits.
